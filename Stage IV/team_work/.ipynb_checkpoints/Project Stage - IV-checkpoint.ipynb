{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1916ee562893415aa81f03d60bc4dc63",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Project Stage - IV (Basic Machine Learning)  ddl: 04/28/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7feaea4ff2ca45b1b70beae9841dd917",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Goals\n",
    "\n",
    "The goal of Stage IV is to utlize machine learning and statistical models to predict the trend of COVID-19 cases / deaths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "430af90a63f1452a8af660fa55e48c7b",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Tasks for Stage IV:\n",
    "\n",
    "#### Task 1: (70 pts)\n",
    "- Team: (30)\n",
    "    - Develop Linear and Non-Linear (polynomial) regression models for predicting cases and deaths in US. \n",
    "        - Start your data from the first day of infections in US. X-Axis - number of days since the first case, Y-Axis - number of new cases and deaths.\n",
    "        - Calculate and report Root Mean Square Error (RMSE) for your models (linear and non-linear). Discuss bias versus variance tradeoff.\n",
    "        - Plot trend line along for the data along with the forecast of 1 week ahead. \n",
    "        - Describe the trends as compared to other countries. \n",
    "- Member: (40 pts)\n",
    "    - Utilize Linear and Non-Linear (polynomial) regression models to compare trends for a single state (each member should choose different state) and its counties (top 5 with highest number of cases). Start your data from the first day of infections. \n",
    "        - X-Axis - number of days since the first case, Y - Axis number of new cases and deaths. Calcluate error using RMSE.\n",
    "        - Identify which counties are most at risk. Model for top 5 counties with cases within a state and describe their trends.\n",
    "        - Utilize the hospital data to calculate the point of no return for a state. Use percentage occupancy / utilization to see which states are close and what their trend looks like.\n",
    "        - Perform hypothesis tests on questions identified in Stage II\n",
    "            - e.x. *Does higher employment data (overall employment numbers) lead to higher covid case numbers or more rapid increase in covid cases.*. Here you would compare the covid cases to the state or county level enrichment data to prove or disprove your null hypothesis. In this case there will be a two tail - two sample t-test to see if there is a difference and then one-tail - two sample t-test to show higher or lower.\n",
    "        - Depending on your type of data you can also perform Chi-square test for categorical hypothesis testing. \n",
    "\n",
    "    \n",
    "#### Task 2: (30 pts)\n",
    "- Member:\n",
    "    - For each of the aforemention analysis plot graphs,\n",
    "        - trend line\n",
    "        - confidence intervals (error in prediction)\n",
    "        - prediction path (forecast)\n",
    "\n",
    "**Deliverable**\n",
    "- Each member creates separate notebooks for member tasks. Upload all notebooks and reports to Canvas. Do not submit to Github, at least before the submission deadline, to avoid potential plagiarism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "37f4280861d0409cad71cd9bceaf2fb7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1681,
    "execution_start": 1681327962991,
    "source_hash": "39b9fccc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from mlxtend.evaluate import bias_variance_decomp\n",
    "from math import sqrt\n",
    "from sklearn.svm import SVR\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "deca5c9c454846f7ad178e5dce0505a9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1047,
    "execution_start": 1681327964674,
    "source_hash": "d639dc41"
   },
   "outputs": [],
   "source": [
    "confirmed_cases = pd.read_csv('data/covid_confirmed_usafacts.csv')\n",
    "confirmed_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "14f055ea4b5f4c309b5bf5f9e1e84c41",
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 0,
     "pageSize": 10,
     "sortBy": []
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 605,
    "execution_start": 1681327965744,
    "scrolled": false,
    "source_hash": "85777d33"
   },
   "outputs": [],
   "source": [
    "confirmed_deaths = pd.read_csv('data/covid_deaths_usafacts.csv')\n",
    "confirmed_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "589616d576c84f45abb2f4f4f283d0c2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1681327985554,
    "source_hash": "b623e53d"
   },
   "outputs": [],
   "source": [
    "def question1(confirmed_cases):\n",
    "    group_cases_USA = confirmed_cases.sum()\n",
    "    group_cases_USA = group_cases_USA.iloc[4:]\n",
    "\n",
    "    temp = group_cases_USA.index\n",
    "\n",
    "    X =[]\n",
    "    for i in range(len(temp)):\n",
    "        X.append(i)\n",
    "    Y= group_cases_USA.values\n",
    "    X = np.array(X)\n",
    "    X= X.reshape(-1,1)\n",
    "    Y = Y.astype('int')\n",
    "\n",
    "    X_train_cases, X_test_cases, y_train_cases, y_test_cases = train_test_split(X, Y, test_size=.3)\n",
    "\n",
    "    lrg = LogisticRegression()\n",
    "    lrl = LinearRegression()\n",
    "    lrg.fit(X_train_cases,y_train_cases)\n",
    "    lrl.fit(X_train_cases,y_train_cases)\n",
    "    \n",
    "    pr = LinearRegression()\n",
    "    poly = PolynomialFeatures(degree=3)\n",
    "    X_poly_train = poly.fit_transform(X_train_cases)\n",
    "    X_poly_test = poly.transform(X_test_cases)\n",
    "    pr.fit(X_poly_train, y_train_cases)\n",
    "\n",
    "    y_pred_lrl = lrl.predict(X_test_cases)\n",
    "    y_pred_lrg = lrg.predict(X_test_cases)\n",
    "    y_pred_pr = pr.predict(X_poly_test)\n",
    "\n",
    "    rmse_lrl = sqrt(abs(mean_squared_error(y_test_cases, np.abs(y_pred_lrl))))\n",
    "    rmse_lrg = sqrt(abs(mean_squared_error(y_test_cases, (y_pred_lrg))))\n",
    "    rmse_pr = sqrt(abs(mean_squared_error(y_test_cases, y_pred_pr)))\n",
    "\n",
    "    print(f'Logistic regression Root Mean Square Error (RMSE): {round(rmse_lrg,2)}')\n",
    "    print(f'Linear regression Root Mean Square Error (RMSE): {round(rmse_lrl,2)}')\n",
    "    print(f'Polynomial regression Root Mean Square Error (RMSE): {round(rmse_pr,2)}')\n",
    "    \n",
    "    diff_pred_act = y_test_cases - y_pred_lrg\n",
    "    sum_diff = sum(diff_pred_act)\n",
    "    bias = sum_diff/len(y_test_cases)\n",
    "    print(f'Bias logistic regression model: {round(bias,2)}')\n",
    "    \n",
    "    pred_var = y_pred_lrg.var()\n",
    "    print(f'Variance logistic regression model: {round(pred_var)}')\n",
    "    \n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.title('Cases along with trend line')\n",
    "    plt.plot(X,\n",
    "        lrg.predict(X),\n",
    "        color='b',\n",
    "        label = 'Prediction')\n",
    "    \n",
    "    plt.plot(X, \n",
    "             pr.predict(X_poly_test),\n",
    "             color='lime', \n",
    "             label='polynomial')\n",
    "\n",
    "    plt.scatter(X,Y,facecolor=\"none\",\n",
    "        edgecolor='m',\n",
    "        s=10,\n",
    "           label = 'Actual')\n",
    "    plt.legend(\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, 1.1),\n",
    "    ncol=1,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    next_week = []\n",
    "    for i in range(7):\n",
    "        next_week.append(i + len(X))\n",
    "    next_week = np.array(next_week)\n",
    "    next_week= next_week.reshape(-1,1)\n",
    "\n",
    "    y_next_week = lrg.predict(next_week)\n",
    "    X_next = np.append(X, next_week)\n",
    "    X_next = X_next.reshape(-1,1)\n",
    "    \n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.title('Cases along with trend line and forecast of 1 week ahead')\n",
    "    plt.plot(X_next,\n",
    "            lrg.predict(X_next),\n",
    "            color='b',\n",
    "            label = 'Prediction')\n",
    "\n",
    "    plt.scatter(X,Y,facecolor=\"none\",\n",
    "            edgecolor='m',\n",
    "            s=10,\n",
    "               label = 'Actual')\n",
    "    \n",
    "    plt.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1(confirmed_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE of both logistic regression and linear regression model decreases as the size of the training set increases, and it decreases the most for the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the calculated bias is very low, in comparison to the high variance. This means that our logistic regression model is underfitting and is not able to fully capture the pattern in our dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Deaths in USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1(confirmed_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "59c15a7eee39482f85b4de4d2fabc0aa",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
